{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWmmO8GL4rGb"
   },
   "source": [
    "# GR5243 Project 3 Main script\n",
    "## for Improved Model (SRCNN)\n",
    "### Group 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG9ICjUp5blg"
   },
   "source": [
    "## Step 0: import libraries and specify directories.\n",
    "Import libraries and set the working directory to the SRSNN folder. In order to obain reproducible results, random.seed() randomization is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GI-qippA4oVh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "import pprint\n",
    "import random\n",
    "import math\n",
    "random.seed(83)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEnQxDz06V3C"
   },
   "source": [
    "## Step 1: utilities. \n",
    "Define funtions used later in the model and main part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq6vkwtj4oVl"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#                                    #\n",
    "#          FOR TRAINING ONLY         #\n",
    "#                                    #\n",
    "###################################### \n",
    "\n",
    "def load_data1(is_train):\n",
    "    if is_train:\n",
    "        data_dir1 = os.path.join(os.getcwd(), 'train_set', \"LR\") # Join the Train dir to current directory\n",
    "        data1 = glob.glob(os.path.join(data_dir1, \"*.jpg\"))[:300] + glob.glob(os.path.join(data_dir1, \"*.jpg\"))[500:800] + glob.glob(os.path.join(data_dir1, \"*.jpg\"))[1000:1200]# make set of all dataset file path\n",
    "        \n",
    "        data_dir2 = os.path.join(os.getcwd(), 'train_set', \"HR\") # Join the Train dir to current directory\n",
    "        data2 = glob.glob(os.path.join(data_dir2, \"*.jpg\"))[:300] + glob.glob(os.path.join(data_dir2, \"*.jpg\"))[500:800] + glob.glob(os.path.join(data_dir2, \"*.jpg\"))[1000:1200] # make set of all dataset file path\n",
    "    return data1, data2\n",
    "\n",
    "  \n",
    "def make_sub_data1(data1,data2, padding, config):\n",
    "    \"\"\"\n",
    "        Make the sub_data set\n",
    "        Args:\n",
    "            data : the set of all file path \n",
    "            padding : the image padding of input to label\n",
    "            config : the all flags\n",
    "    \"\"\"\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "    for i in range(len(data1)):\n",
    "        if config.is_train:\n",
    "            input_=data1[i]\n",
    "            label_=data2[i]\n",
    "            \n",
    "            input_=cv2.imread(input_)\n",
    "            input_=cv2.resize(input_,None,fx = 2 ,fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "            label_=cv2.imread(label_)\n",
    "            \n",
    "        if len(input_.shape) == 3: # is color\n",
    "            h, w, c = input_.shape\n",
    "        else:\n",
    "            h, w = input_.shape # is grayscale\n",
    " \n",
    "        nx, ny = 0, 0\n",
    "        for x in range(0, h - config.image_size + 1, config.stride):\n",
    "            nx += 1; ny = 0\n",
    "            for y in range(0, w - config.image_size + 1, config.stride):\n",
    "                ny += 1\n",
    "\n",
    "                sub_input = input_[x: x + config.image_size, y: y + config.image_size] # 33 * 33\n",
    "                sub_label = label_[x + padding: x + padding + config.label_size, y + padding: y + padding + config.label_size] # 21 * 21\n",
    "\n",
    "                # Reshape the subinput and sublabel\n",
    "                sub_input = sub_input.reshape([config.image_size, config.image_size, config.c_dim])\n",
    "                sub_label = sub_label.reshape([config.label_size, config.label_size, config.c_dim])\n",
    "                # Normialize\n",
    "                sub_input =  sub_input / 255.0\n",
    "                sub_label =  sub_label / 255.0\n",
    "\n",
    "                # Add to sequence\n",
    "                sub_input_sequence.append(sub_input)\n",
    "                sub_label_sequence.append(sub_label)\n",
    "\n",
    "    # NOTE: The nx, ny can be ignore in train\n",
    "    return sub_input_sequence, sub_label_sequence, nx, ny\n",
    "\n",
    "  \n",
    "def make_data_hf1(input_, label_, config):\n",
    "    \"\"\"\n",
    "        Make input data as h5 file format\n",
    "        Depending on \"is_train\" (flag value), savepath would be change.\n",
    "    \"\"\"\n",
    "    # Check the check dir, if not, create one\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),config.checkpoint_dir)):\n",
    "        os.makedirs(os.path.join(os.getcwd(),config.checkpoint_dir))\n",
    "\n",
    "    if config.is_train:\n",
    "        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/train.h5')\n",
    "\n",
    "    with h5py.File(savepath, 'w') as hf:\n",
    "        hf.create_dataset('input', data=input_)\n",
    "        hf.create_dataset('label', data=label_)\n",
    "        \n",
    "        \n",
    "def input_setup1(config):\n",
    "    \"\"\"\n",
    "        Read image files and make their sub-images and saved them as a h5 file format\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data path, if is_train False, get test data\n",
    "    data1,data2 = load_data1(config.is_train)\n",
    "\n",
    "    padding = abs(config.image_size - config.label_size) // 2\n",
    "\n",
    "    # Make sub_input and sub_label, if is_train false more return nx, ny\n",
    "    sub_input_sequence, sub_label_sequence, nx, ny = make_sub_data1(data1,data2, padding, config)\n",
    "\n",
    "\n",
    "    # Make list to numpy array. With this transform\n",
    "    arrinput = np.asarray(sub_input_sequence) # [?, 33, 33, 3]\n",
    "    arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 3]\n",
    "\n",
    "    make_data_hf1(arrinput, arrlabel, config)\n",
    "    \n",
    "    return nx, ny\n",
    "\n",
    "\n",
    "def checkpoint_dir1(config):\n",
    "    if config.is_train:\n",
    "        return os.path.join('./{}'.format(config.checkpoint_dir), \"train.h5\")\n",
    "      \n",
    "\n",
    "def read_data1(path):\n",
    "    \"\"\"\n",
    "        Read h5 format data file\n",
    "\n",
    "        Args:\n",
    "            path: file path of desired file\n",
    "            data: '.h5' file format that contains  input values\n",
    "            label: '.h5' file format that contains label values \n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        input_ = np.array(hf.get('input'))\n",
    "        label_ = np.array(hf.get('label'))\n",
    "        return input_, label_\n",
    "\n",
    "      \n",
    "######################################\n",
    "#                                    #\n",
    "#          FOR TESTING ONLY          #\n",
    "#                                    #\n",
    "######################################    \n",
    "    \n",
    "\n",
    "# Get the Image\n",
    "def imread(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img\n",
    "\n",
    "  \n",
    "def imsave(image, path, config):\n",
    "    #checkimage(image)\n",
    "    # Check the check dir, if not, create one\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),config.result_dir)):\n",
    "        os.makedirs(os.path.join(os.getcwd(),config.result_dir))\n",
    "    # NOTE: because normial, we need mutlify 255 back    \n",
    "    cv2.imwrite(os.path.join(os.getcwd(),path),image * 255.)\n",
    "\n",
    "    \n",
    "def checkimage(image):\n",
    "    cv2.imshow('test', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    \n",
    "def modcrop(img, scale = 3):\n",
    "    \"\"\"\n",
    "        To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
    "    \"\"\"\n",
    "    # Check the image is grayscale\n",
    "    if len(img.shape) ==3:\n",
    "        h, w, _ = img.shape\n",
    "        h = (h // scale) * scale\n",
    "        w = (w // scale) * scale\n",
    "        img = img[0:h, 0:w, :]\n",
    "    else:\n",
    "        h, w = img.shape\n",
    "        h = (h // scale) * scale\n",
    "        w = (w // scale) * scale\n",
    "        img = img[0:h, 0:w]\n",
    "    return img\n",
    "\n",
    "  \n",
    "def checkpoint_dir(config):\n",
    "    if config.is_train:\n",
    "        return os.path.join('./{}'.format(config.checkpoint_dir), 'train.h5')\n",
    "    else:\n",
    "        return os.path.join('./{}'.format(config.checkpoint_dir), 'test.h5')\n",
    "\n",
    "      \n",
    "def prepare_data(dataset='Train',Input_img=''):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            dataset: choose train dataset or test dataset\n",
    "            For train dataset, output data would be ['.../t1.bmp', '.../t2.bmp',..., 't99.bmp']\n",
    "    \"\"\"\n",
    "    if dataset == 'Train':\n",
    "        data_dir = os.path.join(os.getcwd(), dataset) # Join the Train dir to current directory\n",
    "        data = glob.glob(os.path.join(data_dir, '*.*')) # make set of all dataset file path\n",
    "    else:\n",
    "        if Input_img !='':\n",
    "            data = [os.path.join(os.getcwd(),Input_img)]\n",
    "        else:\n",
    "            data_dir = os.path.join(os.path.join(os.getcwd(), dataset), 'Set5')\n",
    "            data = glob.glob(os.path.join(data_dir, '*.*')) # make set of all dataset file path\n",
    "    print(data)\n",
    "    return data\n",
    "\n",
    "  \n",
    "def load_data(is_train, test_img):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            is_train: decides if we choose train dataset or test dataset\n",
    "            For train dataset, output data would be ['.../t1.bmp', '.../t2.bmp',..., 't99.bmp']\n",
    "    \"\"\"\n",
    "    if is_train:\n",
    "        data_dir = os.path.join(os.getcwd(), 'Train') # Join the Train dir to current directory\n",
    "        data = glob.glob(os.path.join(data_dir, '*.*')) # make set of all dataset file path\n",
    "    else:\n",
    "        if test_img != '':\n",
    "            return [os.path.join(os.getcwd(), test_img)]\n",
    "        data_dir = os.path.join(os.path.join(os.getcwd(), 'Test'), 'Set5')\n",
    "        data = glob.glob(os.path.join(data_dir, '*.*')) # make set of all dataset file path\n",
    "    return data\n",
    "\n",
    "  \n",
    "def make_sub_data2(data, padding, config):\n",
    "    \"\"\"\n",
    "        Make the sub_data set\n",
    "        Args:\n",
    "            data : the set of all file path \n",
    "            padding : the image padding of input to label\n",
    "            config : the all flags\n",
    "    \"\"\"\n",
    "    sub_input_sequence = []\n",
    "#     sub_label_sequence = []\n",
    "    for i in range(len(data)):\n",
    "        input_ = cv2.imread(data[i])\n",
    "        input_=cv2.resize(input_,None,fx = 2 ,fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        if len(input_.shape) == 3: # is color\n",
    "            h, w, c = input_.shape\n",
    "        else:\n",
    "            h, w = input_.shape # is grayscale\n",
    "\n",
    "        nx, ny = 0, 0\n",
    "        for x in range(0, h - config.image_size + 1, config.stride):\n",
    "            nx += 1; ny = 0\n",
    "            for y in range(0, w - config.image_size + 1, config.stride):\n",
    "                ny += 1\n",
    "\n",
    "                sub_input = input_[x: x + config.image_size, y: y + config.image_size] # 33 * 33\n",
    "#                 sub_label = label_[x + padding: x + padding + config.label_size, y + padding: y + padding + config.label_size] # 21 * 21\n",
    "\n",
    "                # Reshape the subinput and sublabel\n",
    "                sub_input = sub_input.reshape([config.image_size, config.image_size, config.c_dim])\n",
    "#                 sub_label = sub_label.reshape([config.label_size, config.label_size, config.c_dim])\n",
    "                # Normialize\n",
    "                sub_input =  sub_input / 255.0\n",
    "#                 sub_label =  sub_label / 255.0\n",
    "\n",
    "                # Add to sequence\n",
    "                sub_input_sequence.append(sub_input)\n",
    "#                 sub_label_sequence.append(sub_label)\n",
    "\n",
    "#     return sub_input_sequence, sub_label_sequence, nx, ny\n",
    "    return sub_input_sequence, nx, ny\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "        Read h5 format data file\n",
    "\n",
    "        Args:\n",
    "            path: file path of desired file\n",
    "            data: '.h5' file format that contains  input values\n",
    "            label: '.h5' file format that contains label values \n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        input_ = np.array(hf.get('input'))\n",
    "        label_ = np.array(hf.get('label'))\n",
    "        return input_, label_\n",
    "\n",
    "      \n",
    "def make_data_hf2(input_, config):\n",
    "    \"\"\"\n",
    "        Make input data as h5 file format\n",
    "        Depending on 'is_train' (flag value), savepath would be change.\n",
    "    \"\"\"\n",
    "    # Check the check dir, if not, create one\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),config.checkpoint_dir)):\n",
    "        os.makedirs(os.path.join(os.getcwd(),config.checkpoint_dir))\n",
    "\n",
    "    if config.is_train:\n",
    "        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/train.h5')\n",
    "    else:\n",
    "        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/test.h5')\n",
    "\n",
    "    with h5py.File(savepath, 'w') as hf:\n",
    "        hf.create_dataset('input', data=input_)\n",
    "\n",
    "        \n",
    "def merge(images, size, c_dim):\n",
    "    \"\"\"\n",
    "        images is the sub image set, merge it\n",
    "    \"\"\"\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    print(h, w)\n",
    "    print(size[0], size[1])\n",
    "    img = np.zeros((h*size[0], w*size[1], c_dim))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j * h : j * h + h, i * w : i * w + w, :] = image\n",
    "    return img\n",
    "\n",
    "  \n",
    "def input_setup2(config):\n",
    "    \"\"\"\n",
    "        Read image files and make their sub-images and saved them as a h5 file format\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data path, if is_train False, get test data\n",
    "    data = load_data(config.is_train, config.test_img)\n",
    "\n",
    "    padding = abs(config.image_size - config.label_size) // 2\n",
    "\n",
    "    # Make sub_input and sub_label, if is_train false more return nx, ny\n",
    "#     sub_input_sequence, sub_label_sequence, nx, ny = make_sub_data2(data, padding, config)\n",
    "    sub_input_sequence, nx, ny = make_sub_data2(data, padding, config)\n",
    "\n",
    "    # Make list to numpy array. With this transform\n",
    "    arrinput = np.asarray(sub_input_sequence) # [?, 33, 33, 3]\n",
    "#     arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 3]\n",
    "\n",
    "    make_data_hf2(arrinput, config)\n",
    "    return nx, ny\n",
    "\n",
    "  \n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPmtTY2J78Ji"
   },
   "source": [
    "## Step 2: the SRCNN model. \n",
    "Define a SRCNN `class` which can train and test data.\n",
    "\n",
    "In the next step, an instance of will be created and used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MKPNpBW4oVo"
   },
   "outputs": [],
   "source": [
    "class SRCNN(object):\n",
    "\n",
    "    def __init__(self,sess, image_size, label_size,c_dim):\n",
    "        self.sess = sess\n",
    "        self.image_size = image_size\n",
    "        self.label_size = label_size\n",
    "        self.c_dim = c_dim\n",
    "        self.build_model()\n",
    "        \n",
    "        \n",
    "    def train(self, config):\n",
    "            # NOTE : if train, the nx, ny are ingnored\n",
    "            nx, ny = input_setup1(config)\n",
    "            print(0)\n",
    "            data_dir = checkpoint_dir1(config)\n",
    "            print(data_dir)\n",
    "            \n",
    "            input_, label_ = read_data1(data_dir)\n",
    "            print('input_ =', input_[0:3])\n",
    "            #print(input_)\n",
    "            # Stochastic gradient descent with the standard backpropagation\n",
    "            #self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)\n",
    "            self.train_op = tf.train.AdamOptimizer(learning_rate=config.learning_rate).minimize(self.loss)\n",
    "            tf.global_variables_initializer().run()\n",
    "            counter = 0\n",
    "            time_ = time.time()\n",
    "            print('time_: ', time_)\n",
    "            # Train\n",
    "            if config.is_train:\n",
    "                print(\"Now Start Training...\")\n",
    "                for ep in range(config.epoch):\n",
    "                    # Run by batch images\n",
    "                    batch_idxs = len(input_) // config.batch_size\n",
    "                    print('len(input_) =', batch_idxs)\n",
    "                    for idx in range(0, batch_idxs):\n",
    "                        batch_images = input_[idx * config.batch_size : (idx + 1) * config.batch_size]\n",
    "                        batch_labels = label_[idx * config.batch_size : (idx + 1) * config.batch_size]\n",
    "                        counter += 1\n",
    "                        _, err = self.sess.run([self.train_op, self.loss], feed_dict={self.images: batch_images, self.labels: batch_labels})\n",
    "\n",
    "                        if counter % 10 == 0:\n",
    "                            print(\"Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]\" % ((ep+1), counter, time.time()-time_, err))\n",
    "                            #print(label_[1] - self.pred.eval({self.images: input_})[1],'loss:]',err)\n",
    "                        if counter % 10 == 0:\n",
    "                            self.save(config.checkpoint_dir, counter)\n",
    "\n",
    "                            \n",
    "    def build_model(self):\n",
    "        self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name='images')\n",
    "        self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name='labels')\n",
    "        \n",
    "        self.weights = {\n",
    "            'w1': tf.Variable(tf.random_normal([9, 9, self.c_dim, 128], stddev=1e-3), name='w1'),\n",
    "            'w2': tf.Variable(tf.random_normal([1, 1, 128, 64], stddev=1e-3), name='w2'),\n",
    "            'w3': tf.Variable(tf.random_normal([5, 5, 64, self.c_dim], stddev=1e-3), name='w3')\n",
    "        }\n",
    "\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.zeros([128], name='b1')),\n",
    "            'b2': tf.Variable(tf.zeros([64], name='b2')),\n",
    "            'b3': tf.Variable(tf.zeros([self.c_dim], name='b3'))\n",
    "        }\n",
    "        \n",
    "        self.pred = self.model()\n",
    "        self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n",
    "        self.saver = tf.train.Saver() # To save checkpoint\n",
    "\n",
    "        \n",
    "    def model(self):\n",
    "        conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights['w1'], strides=[1,1,1,1], padding='VALID') + self.biases['b1'])\n",
    "        conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights['w2'], strides=[1,1,1,1], padding='SAME') + self.biases['b2'])\n",
    "        conv3 = tf.nn.conv2d(conv2, self.weights['w3'], strides=[1,1,1,1], padding='VALID') + self.biases['b3'] # This layer don't need ReLU\n",
    "        return conv3\n",
    "\n",
    "    \n",
    "    def save(self, checkpoint_dir, step):\n",
    "        \"\"\"\n",
    "            To save the checkpoint use to test or pretrain\n",
    "        \"\"\"\n",
    "        model_name = \"SRCNN.model\"\n",
    "        model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "             os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, model_name),global_step=step)\n",
    "        \n",
    "        \n",
    "    def test(self, config):\n",
    "        print('Testing...')\n",
    "        nx, ny = input_setup2(config)\n",
    "        data_dir = checkpoint_dir(config)\n",
    "        input_, label_ = read_data(data_dir)\n",
    "        self.load(config.checkpoint_dir)\n",
    "        # Test\n",
    "        result = self.pred.eval({self.images: input_})\n",
    "        image = merge(result, [nx, ny], self.c_dim)\n",
    "     \n",
    "        base, ext = os.path.basename(config.test_img).split('.')\n",
    "        \n",
    "        test_files =random.sample(files, len(files)//5) # a list of strings (the paths of each image)\n",
    "        LR_image = imread(os.path.join(os.path.join(os.getcwd(),'train_set',\"LR\"), base + '.jpg'))\n",
    "        LR_h = LR_image.shape[1]*2\n",
    "        LR_w = LR_image.shape[0]*2  \n",
    "        image = cv2.resize(image,(LR_h,LR_w))\n",
    "        \n",
    "        imsave(image, os.path.join(config.result_dir, base + '.png'), config)\n",
    "\n",
    "        \n",
    "    def load(self, checkpoint_dir):\n",
    "        \"\"\"\n",
    "            To load the checkpoint use to test or pretrain\n",
    "        \"\"\"\n",
    "        model_dir = '%s_%s' % ('srcnn', self.label_size)# give the model name by label_size\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        \n",
    "        # Check the checkpoint is exist \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_path = str(ckpt.model_checkpoint_path) # convert the unicode to string\n",
    "            self.saver.restore(self.sess, os.path.join(os.getcwd(), ckpt_path))\n",
    "#             print('Success! %s'% ckpt_path)\n",
    "        else:\n",
    "            print('Loading failed.')\n",
    "            \n",
    "        \n",
    "    def save(self, checkpoint_dir, step):\n",
    "        \"\"\"\n",
    "            To save the checkpoint use to test or pretrain\n",
    "        \"\"\"\n",
    "        model_name = 'SRCNN.model'\n",
    "        model_dir = '%s_%s' % ('srcnn', self.label_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "             os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,\n",
    "                        os.path.join(checkpoint_dir, model_name),\n",
    "                        global_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5EOMGtq9BOI"
   },
   "source": [
    "## Step 3: the main part. \n",
    "In this cell, we first establish a `class this_config()` which decides all the parameters of the model.\n",
    "\n",
    "We then create an instance `class SRCNN()` and use it to train and/or test data.\n",
    "\n",
    "### Instruction\n",
    "- For training and testing (with PSNR computed), run the cell below.\n",
    "- For testing (with PSNR computed only), comment line 27 `srcnn.train(FLAGS)` and run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pf2GkFiY4oVr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running...\n",
      "/Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN\n",
      "Saving  1 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1157.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  2 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0249.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "16 29\n",
      "Saving  3 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1143.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 28\n",
      "Saving  4 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0498.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  5 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0467.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  6 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0301.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  7 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0315.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "29 16\n",
      "Saving  8 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0473.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  9 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1023.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "27 18\n",
      "Saving  10 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0329.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 28\n",
      "Saving  11 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1037.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  12 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0842.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "23 23\n",
      "Saving  13 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0856.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "28 17\n",
      "Saving  14 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0103.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  15 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0665.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "20 25\n",
      "Saving  16 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0671.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 28\n",
      "Saving  17 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1209.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 28\n",
      "Saving  18 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0117.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "24 21\n",
      "Saving  19 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1221.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "26 19\n",
      "Saving  20 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0659.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  21 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0881.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  22 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0895.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  23 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1235.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 28\n",
      "Saving  24 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0894.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  25 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1234.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  26 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1220.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n",
      "18 28\n",
      "Saving  27 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0880.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 28\n",
      "Saving  28 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0658.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "13 32\n",
      "Saving  29 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0670.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "23 23\n",
      "Saving  30 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0116.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  31 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1208.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  32 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0102.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "16 29\n",
      "Saving  33 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0664.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  34 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0857.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  35 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0843.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 28\n",
      "Saving  36 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1036.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "28 17\n",
      "Saving  37 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0328.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 28\n",
      "Saving  38 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1022.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  39 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0314.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "16 29\n",
      "Saving  40 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0472.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  41 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0466.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  42 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0300.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "17 29\n",
      "Saving  43 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0499.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "16 29\n",
      "Saving  44 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1142.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "24 22\n",
      "Saving  45 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0248.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 27\n",
      "Saving  46 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1156.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "24 22\n",
      "Saving  47 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0260.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  48 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0506.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  49 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0512.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  50 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0274.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "16 29\n",
      "Saving  51 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1181.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "26 19\n",
      "Saving  52 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1195.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "19 26\n",
      "Saving  53 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_0738.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n",
      "19 26\n",
      "Saving  54 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1426.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "18 28\n",
      "Saving  55 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1340.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n",
      "21 21\n",
      "14 32\n",
      "Saving  56 / 300 :  /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/train_set/LR/img_1354.jpg \n",
      "\n",
      "Testing...\n",
      "INFO:tensorflow:Restoring parameters from /Users/wanyiellenzheng/Documents/GitHub/Fall2018-Proj3-Sec2-grp7/TensorFlow-SRCNN/checkpoint1/srcnn_21/SRCNN.model-80\n"
     ]
    }
   ],
   "source": [
    "class this_config():\n",
    "    def __init__(self, is_train=True): \n",
    "        self.epoch = 12\n",
    "        self.image_size = 33\n",
    "        self.label_size = 21\n",
    "        self.c_dim = 3\n",
    "        self.is_train = is_train\n",
    "        self.scale = 3\n",
    "        self.stride = 21\n",
    "        self.checkpoint_dir = \"checkpoint1\"\n",
    "        self.learning_rate = 1e-4\n",
    "        self.batch_size = 128\n",
    "        self.result_dir = 'result'\n",
    "        self.test_img = '' # Do not change this.\n",
    "        \n",
    "arg = this_config()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Start running...\")\n",
    "    FLAGS = arg\n",
    "    srcnn = SRCNN(sess,\n",
    "                  image_size = FLAGS.image_size,\n",
    "                  label_size = FLAGS.label_size,\n",
    "                  c_dim = FLAGS.c_dim)\n",
    "    \n",
    "    # Training\n",
    "#     srcnn.train(FLAGS)\n",
    "    \n",
    "    # Testing\n",
    "    print(os.getcwd())\n",
    "    files = glob.glob(os.path.join(os.getcwd(), 'train_set', 'LR', '*.jpg'))\n",
    "    test_files = files[400:500] + files[900:1000] + files[1400:1500]         \n",
    "                 # a list of strings (the paths of each image)\n",
    "    \n",
    "    FLAGS.is_train = False\n",
    "    count = 1\n",
    "    for f in test_files:\n",
    "        FLAGS.test_img = f\n",
    "        print('Saving ', count, '/', len(test_files), ': ', FLAGS.test_img, '\\n')\n",
    "        count += 1\n",
    "        srcnn.test(FLAGS)\n",
    "        \n",
    "    # PSNR\n",
    "    #result_files = glob.glob(os.path.join(os.getcwd(), 'result', '*.png'))\n",
    "    res_imgs = glob.glob(os.path.join(os.getcwd(), 'result', '*.png'))\n",
    "    psnr_total = []\n",
    "#     print(test_files[0:3])\n",
    "#     print(res_imgs[0:3])\n",
    "    for test_img, res_img in zip(test_files, res_imgs):   \n",
    "        print(test_img)\n",
    "        print(res_img)\n",
    "        img1 = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0] \n",
    "        img2 = cv2.imread(res_img, cv2.IMREAD_COLOR)\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0] \n",
    "        img1 = cv2.resize(img1,(img2.shape[1],img2.shape[0]))\n",
    "        psnr_total.append(psnr(img1,img2))\n",
    "            \n",
    "    print('The PSNR between the ground truth and the test is: ', np.mean(psnr_total))\n",
    "    \n",
    "    # Transcode .png results into .jpg format\n",
    "    for res_img in res_imgs:\n",
    "        img = cv2.imread(j)\n",
    "        cv2.imwrite(j[:-3] + 'jpg', img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
