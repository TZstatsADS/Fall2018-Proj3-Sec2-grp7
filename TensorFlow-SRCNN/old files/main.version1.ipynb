{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(is_train):\n",
    "    if is_train:\n",
    "        data_dir1 = os.path.join(os.getcwd(), 'train_set', \"LR0\") # Join the Train dir to current directory\n",
    "        data1 = glob.glob(os.path.join(data_dir1, \"*.jpg\")) # make set of all dataset file path\n",
    "        print(data_dir1, data1[0:5])\n",
    "        data_dir2 = os.path.join(os.getcwd(), 'train_set', \"HR0\") # Join the Train dir to current directory\n",
    "        data2 = glob.glob(os.path.join(data_dir2, \"*.jpg\")) # make set of all dataset file path\n",
    "    return data1,data2\n",
    "\n",
    "\n",
    "def make_sub_data(data1,data2, padding, config):\n",
    "    \"\"\"\n",
    "        Make the sub_data set\n",
    "        Args:\n",
    "            data : the set of all file path \n",
    "            padding : the image padding of input to label\n",
    "            config : the all flags\n",
    "    \"\"\"\n",
    "    sub_input_sequence = []\n",
    "    sub_label_sequence = []\n",
    "    for i in range(len(data1)):\n",
    "        if config.is_train:\n",
    "            input_=data1[i]\n",
    "            label_=data2[i]\n",
    "            \n",
    "            \n",
    "            input_=cv2.imread(input_)\n",
    "            input_=cv2.resize(input_,None,fx = 2 ,fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "            label_=cv2.imread(label_)\n",
    "            \n",
    "        if len(input_.shape) == 3: # is color\n",
    "            h, w, c = input_.shape\n",
    "        else:\n",
    "            h, w = input_.shape # is grayscale\n",
    " \n",
    "        for x in range(0, h - config.image_size + 1, config.stride):\n",
    "            for y in range(0, w - config.image_size + 1, config.stride):\n",
    "\n",
    "                sub_input = input_[x: x + config.image_size, y: y + config.image_size] # 33 * 33\n",
    "                sub_label = label_[x + padding: x + padding + config.label_size, y + padding: y + padding + config.label_size] # 21 * 21\n",
    "\n",
    "\n",
    "                # Reshape the subinput and sublabel\n",
    "                sub_input = sub_input.reshape([config.image_size, config.image_size, config.c_dim])\n",
    "                sub_label = sub_label.reshape([config.label_size, config.label_size, config.c_dim])\n",
    "                # Normialize\n",
    "                sub_input =  sub_input / 255.0\n",
    "                sub_label =  sub_label / 255.0\n",
    "                \n",
    "                #cv2.imshow(\"im1\",sub_input)\n",
    "                #cv2.imshow(\"im2\",sub_label)\n",
    "                #cv2.waitKey(0)\n",
    "\n",
    "                # Add to sequence\n",
    "                sub_input_sequence.append(sub_input)\n",
    "                sub_label_sequence.append(sub_label)\n",
    "\n",
    "    return sub_input_sequence, sub_label_sequence\n",
    "\n",
    "def make_data_hf(input_, label_, config):\n",
    "    \"\"\"\n",
    "        Make input data as h5 file format\n",
    "        Depending on \"is_train\" (flag value), savepath would be change.\n",
    "    \"\"\"\n",
    "    # Check the check dir, if not, create one\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),config.checkpoint_dir)):\n",
    "        os.makedirs(os.path.join(os.getcwd(),config.checkpoint_dir))\n",
    "\n",
    "    if config.is_train:\n",
    "        savepath = os.path.join(os.getcwd(), config.checkpoint_dir + '/train.h5')\n",
    "\n",
    "    with h5py.File(savepath, 'w') as hf:\n",
    "        hf.create_dataset('input', data=input_)\n",
    "        hf.create_dataset('label', data=label_)\n",
    "\n",
    "def input_setup(config):\n",
    "    \"\"\"\n",
    "        Read image files and make their sub-images and saved them as a h5 file format\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data path, if is_train False, get test data\n",
    "    data1,data2 = load_data(config.is_train)\n",
    "\n",
    "    padding = abs(config.image_size - config.label_size) // 2\n",
    "\n",
    "    # Make sub_input and sub_label\n",
    "    sub_input_sequence, sub_label_sequence = make_sub_data(data1,data2, padding, config)\n",
    "\n",
    "\n",
    "    # Make list to numpy array. With this transform\n",
    "    arrinput = np.asarray(sub_input_sequence) # [?, 33, 33, 3]\n",
    "    arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 3]\n",
    "\n",
    "    make_data_hf(arrinput, arrlabel, config)\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "def checkpoint_dir(config):\n",
    "    if config.is_train:\n",
    "        return os.path.join('./{}'.format(config.checkpoint_dir), \"train.h5\")\n",
    "    #else:\n",
    "        #return os.path.join('./{}'.format(config.checkpoint_dir), \"test.h5\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "        Read h5 format data file\n",
    "\n",
    "        Args:\n",
    "            path: file path of desired file\n",
    "            data: '.h5' file format that contains  input values\n",
    "            label: '.h5' file format that contains label values \n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        input_ = np.array(hf.get('input'))\n",
    "        label_ = np.array(hf.get('label'))\n",
    "        return input_, label_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCNN(object):\n",
    "\n",
    "    def __init__(self,sess, image_size, label_size,c_dim):\n",
    "        self.sess = sess\n",
    "        self.image_size = image_size\n",
    "        self.label_size = label_size\n",
    "        self.c_dim = c_dim\n",
    "        self.build_model()\n",
    "        \n",
    "    def train(self, config):\n",
    "        input_setup(config)\n",
    "\n",
    "        data_dir = checkpoint_dir(config)\n",
    "\n",
    "        input_, label_ = read_data(data_dir)\n",
    "        print(input_)\n",
    "        #print(input_)\n",
    "        # Stochastic gradient descent with the standard backpropagation\n",
    "        #self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=config.learning_rate).minimize(self.loss)\n",
    "        tf.global_variables_initializer().run()\n",
    "        counter = 0\n",
    "        time_ = time.time()\n",
    "\n",
    "        # Train\n",
    "        if config.is_train:\n",
    "            print(\"Now Start Training...\")\n",
    "            for ep in range(config.epoch):\n",
    "                # Run by batch images\n",
    "                batch_idxs = len(input_) // config.batch_size\n",
    "                for idx in range(0, batch_idxs):\n",
    "                    batch_images = input_[idx * config.batch_size : (idx + 1) * config.batch_size]\n",
    "                    batch_labels = label_[idx * config.batch_size : (idx + 1) * config.batch_size]\n",
    "                    counter += 1\n",
    "                    _, err = self.sess.run([self.train_op, self.loss], feed_dict={self.images: batch_images, self.labels: batch_labels})\n",
    "\n",
    "                    if counter % 10 == 0:\n",
    "                        print(\"Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]\" % ((ep+1), counter, time.time()-time_, err))\n",
    "                        #print(label_[1] - self.pred.eval({self.images: input_})[1],'loss:]',err)\n",
    "                    if counter % 10 == 0:\n",
    "                        self.save(config.checkpoint_dir, counter)\n",
    "\n",
    "                            \n",
    "    def build_model(self):\n",
    "        self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name='images')\n",
    "        self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name='labels')\n",
    "        \n",
    "        self.weights = {\n",
    "            'w1': tf.Variable(tf.random_normal([9, 9, self.c_dim, 64], stddev=1e-3), name='w1'),\n",
    "            'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
    "            'w3': tf.Variable(tf.random_normal([5, 5, 32, self.c_dim], stddev=1e-3), name='w3')\n",
    "        }\n",
    "\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.zeros([64], name='b1')),\n",
    "            'b2': tf.Variable(tf.zeros([32], name='b2')),\n",
    "            'b3': tf.Variable(tf.zeros([self.c_dim], name='b3'))\n",
    "        }\n",
    "        \n",
    "        self.pred = self.model()\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n",
    "\n",
    "        self.saver = tf.train.Saver() # To save checkpoint\n",
    "\n",
    "    def model(self):\n",
    "        conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights['w1'], strides=[1,1,1,1], padding='VALID') + self.biases['b1'])\n",
    "        conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights['w2'], strides=[1,1,1,1], padding='VALID') + self.biases['b2'])\n",
    "        conv3 = tf.nn.conv2d(conv2, self.weights['w3'], strides=[1,1,1,1], padding='VALID') + self.biases['b3'] # This layer don't need ReLU\n",
    "        return conv3\n",
    "\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_dir, step):\n",
    "        \"\"\"\n",
    "            To save the checkpoint use to test or pretrain\n",
    "        \"\"\"\n",
    "        model_name = \"SRCNN.model\"\n",
    "        model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "             os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, model_name),global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello TA!  We are group 7. Thank you for your work for us. Hope you have a happy day!\n",
      "/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0 ['/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0/img_0014.jpg', '/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0/img_0028.jpg', '/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0/img_0029.jpg', '/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0/img_0001.jpg', '/Users/yaoqi/Google Drive/TensorFlow-SRCNN-new/train_set/LR0/img_0015.jpg']\n",
      "[[[[0.50588235 0.58431373 0.62352941]\n",
      "   [0.46666667 0.54901961 0.59607843]\n",
      "   [0.40392157 0.49019608 0.54117647]\n",
      "   ...\n",
      "   [0.1254902  0.13333333 0.10196078]\n",
      "   [0.12941176 0.14117647 0.10980392]\n",
      "   [0.13333333 0.14901961 0.1254902 ]]\n",
      "\n",
      "  [[0.37647059 0.45098039 0.49411765]\n",
      "   [0.36862745 0.44705882 0.49411765]\n",
      "   [0.35294118 0.43529412 0.49019608]\n",
      "   ...\n",
      "   [0.12156863 0.1372549  0.10196078]\n",
      "   [0.12156863 0.1372549  0.10588235]\n",
      "   [0.12156863 0.14117647 0.11764706]]\n",
      "\n",
      "  [[0.16862745 0.23529412 0.28235294]\n",
      "   [0.20784314 0.27843137 0.3254902 ]\n",
      "   [0.26666667 0.34509804 0.4       ]\n",
      "   ...\n",
      "   [0.12156863 0.1372549  0.10196078]\n",
      "   [0.10980392 0.12941176 0.09803922]\n",
      "   [0.10196078 0.12941176 0.10980392]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06666667 0.08627451 0.04313725]\n",
      "   [0.08235294 0.09803922 0.0627451 ]\n",
      "   [0.10980392 0.12156863 0.09411765]\n",
      "   ...\n",
      "   [0.23529412 0.34509804 0.2745098 ]\n",
      "   [0.14901961 0.26666667 0.18823529]\n",
      "   [0.05098039 0.17647059 0.09411765]]\n",
      "\n",
      "  [[0.04313725 0.07058824 0.02352941]\n",
      "   [0.07058824 0.09803922 0.05882353]\n",
      "   [0.11764706 0.14901961 0.11764706]\n",
      "   ...\n",
      "   [0.21960784 0.3254902  0.25882353]\n",
      "   [0.14901961 0.25882353 0.18431373]\n",
      "   [0.07058824 0.18431373 0.10588235]]\n",
      "\n",
      "  [[0.01960784 0.05490196 0.00784314]\n",
      "   [0.05882353 0.10196078 0.05490196]\n",
      "   [0.12941176 0.17647059 0.1372549 ]\n",
      "   ...\n",
      "   [0.24705882 0.35294118 0.29019608]\n",
      "   [0.19215686 0.29803922 0.23137255]\n",
      "   [0.10588235 0.21176471 0.14117647]]]\n",
      "\n",
      "\n",
      " [[[0.05882353 0.14509804 0.16862745]\n",
      "   [0.14901961 0.23921569 0.27058824]\n",
      "   [0.19607843 0.29019608 0.3254902 ]\n",
      "   ...\n",
      "   [0.18039216 0.23529412 0.19215686]\n",
      "   [0.11372549 0.17254902 0.14117647]\n",
      "   [0.08627451 0.15294118 0.1254902 ]]\n",
      "\n",
      "  [[0.0627451  0.14117647 0.16862745]\n",
      "   [0.15294118 0.23529412 0.26666667]\n",
      "   [0.19215686 0.28235294 0.31764706]\n",
      "   ...\n",
      "   [0.15294118 0.21176471 0.16470588]\n",
      "   [0.12941176 0.19215686 0.15686275]\n",
      "   [0.10980392 0.17254902 0.14901961]]\n",
      "\n",
      "  [[0.07058824 0.1372549  0.16862745]\n",
      "   [0.15294118 0.22745098 0.25882353]\n",
      "   [0.18823529 0.27058824 0.30588235]\n",
      "   ...\n",
      "   [0.10980392 0.16862745 0.12156863]\n",
      "   [0.15686275 0.21960784 0.18431373]\n",
      "   [0.14509804 0.21176471 0.18039216]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27843137 0.38431373 0.3254902 ]\n",
      "   [0.20392157 0.30196078 0.24705882]\n",
      "   [0.22352941 0.31764706 0.2627451 ]\n",
      "   ...\n",
      "   [0.21176471 0.25490196 0.22352941]\n",
      "   [0.24313725 0.27843137 0.2627451 ]\n",
      "   [0.24705882 0.2745098  0.2745098 ]]\n",
      "\n",
      "  [[0.28235294 0.38823529 0.32941176]\n",
      "   [0.20784314 0.31372549 0.25490196]\n",
      "   [0.21568627 0.31764706 0.2627451 ]\n",
      "   ...\n",
      "   [0.23529412 0.28235294 0.25882353]\n",
      "   [0.25098039 0.28627451 0.27843137]\n",
      "   [0.24313725 0.2745098  0.2745098 ]]\n",
      "\n",
      "  [[0.26666667 0.37647059 0.31764706]\n",
      "   [0.20784314 0.32156863 0.2627451 ]\n",
      "   [0.20392157 0.32156863 0.26666667]\n",
      "   ...\n",
      "   [0.32156863 0.37254902 0.35686275]\n",
      "   [0.29019608 0.33333333 0.32941176]\n",
      "   [0.23529412 0.2745098  0.2745098 ]]]\n",
      "\n",
      "\n",
      " [[[0.45882353 0.51372549 0.57647059]\n",
      "   [0.65490196 0.71764706 0.77647059]\n",
      "   [0.64313725 0.71372549 0.75686275]\n",
      "   ...\n",
      "   [0.19215686 0.30588235 0.28235294]\n",
      "   [0.19607843 0.34901961 0.31764706]\n",
      "   [0.13333333 0.30196078 0.26666667]]\n",
      "\n",
      "  [[0.47843137 0.53333333 0.59215686]\n",
      "   [0.64705882 0.71372549 0.76862745]\n",
      "   [0.60392157 0.67843137 0.71764706]\n",
      "   ...\n",
      "   [0.18039216 0.29411765 0.27058824]\n",
      "   [0.17647059 0.32941176 0.29803922]\n",
      "   [0.10980392 0.2745098  0.24313725]]\n",
      "\n",
      "  [[0.50980392 0.56470588 0.61960784]\n",
      "   [0.63921569 0.70588235 0.75686275]\n",
      "   [0.5372549  0.61568627 0.65098039]\n",
      "   ...\n",
      "   [0.15686275 0.2745098  0.25098039]\n",
      "   [0.14509804 0.29411765 0.2627451 ]\n",
      "   [0.07058824 0.22745098 0.2       ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.54509804 0.58039216 0.64313725]\n",
      "   [0.67843137 0.72156863 0.78823529]\n",
      "   [0.57647059 0.63137255 0.68627451]\n",
      "   ...\n",
      "   [0.32156863 0.47843137 0.38823529]\n",
      "   [0.30980392 0.47843137 0.38823529]\n",
      "   [0.18039216 0.34117647 0.24705882]]\n",
      "\n",
      "  [[0.5372549  0.58039216 0.64313725]\n",
      "   [0.61176471 0.65882353 0.7254902 ]\n",
      "   [0.47058824 0.52941176 0.58431373]\n",
      "   ...\n",
      "   [0.3254902  0.48235294 0.39215686]\n",
      "   [0.30980392 0.4745098  0.38039216]\n",
      "   [0.16078431 0.32156863 0.22352941]]\n",
      "\n",
      "  [[0.4627451  0.51764706 0.57647059]\n",
      "   [0.43921569 0.49411765 0.55686275]\n",
      "   [0.30588235 0.36470588 0.42352941]\n",
      "   ...\n",
      "   [0.34509804 0.50196078 0.40392157]\n",
      "   [0.31764706 0.4745098  0.37647059]\n",
      "   [0.10980392 0.25882353 0.15686275]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.35686275 0.42352941 0.37254902]\n",
      "   [0.4        0.46666667 0.41568627]\n",
      "   [0.39215686 0.4627451  0.40784314]\n",
      "   ...\n",
      "   [0.3372549  0.42352941 0.35294118]\n",
      "   [0.4627451  0.54509804 0.4745098 ]\n",
      "   [0.43137255 0.51764706 0.45098039]]\n",
      "\n",
      "  [[0.36862745 0.43921569 0.38823529]\n",
      "   [0.41568627 0.48627451 0.43529412]\n",
      "   [0.40784314 0.47843137 0.42745098]\n",
      "   ...\n",
      "   [0.35294118 0.43921569 0.36862745]\n",
      "   [0.45490196 0.54117647 0.47058824]\n",
      "   [0.43137255 0.51764706 0.45098039]]\n",
      "\n",
      "  [[0.4        0.47058824 0.41960784]\n",
      "   [0.43921569 0.50980392 0.45882353]\n",
      "   [0.41176471 0.48627451 0.43529412]\n",
      "   ...\n",
      "   [0.33333333 0.41960784 0.34901961]\n",
      "   [0.43921569 0.52941176 0.45882353]\n",
      "   [0.43529412 0.52941176 0.45882353]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5254902  0.60784314 0.55686275]\n",
      "   [0.50196078 0.58039216 0.52941176]\n",
      "   [0.4745098  0.55294118 0.50196078]\n",
      "   ...\n",
      "   [0.05490196 0.1254902  0.05882353]\n",
      "   [0.01176471 0.08627451 0.01568627]\n",
      "   [0.00784314 0.07843137 0.01176471]]\n",
      "\n",
      "  [[0.54509804 0.62352941 0.57647059]\n",
      "   [0.5372549  0.61568627 0.56862745]\n",
      "   [0.50588235 0.58431373 0.53333333]\n",
      "   ...\n",
      "   [0.04313725 0.11764706 0.05098039]\n",
      "   [0.00784314 0.07843137 0.01176471]\n",
      "   [0.         0.07058824 0.00784314]]\n",
      "\n",
      "  [[0.54901961 0.62745098 0.58039216]\n",
      "   [0.56470588 0.64313725 0.59607843]\n",
      "   [0.52156863 0.6        0.55294118]\n",
      "   ...\n",
      "   [0.04313725 0.11372549 0.04705882]\n",
      "   [0.01176471 0.08235294 0.01568627]\n",
      "   [0.00392157 0.0745098  0.01176471]]]\n",
      "\n",
      "\n",
      " [[[0.17254902 0.23921569 0.17647059]\n",
      "   [0.25098039 0.32156863 0.25490196]\n",
      "   [0.32941176 0.4        0.33333333]\n",
      "   ...\n",
      "   [0.31372549 0.41568627 0.35686275]\n",
      "   [0.34901961 0.44313725 0.38823529]\n",
      "   [0.3372549  0.42745098 0.37254902]]\n",
      "\n",
      "  [[0.16078431 0.23529412 0.16470588]\n",
      "   [0.24705882 0.32156863 0.25098039]\n",
      "   [0.34117647 0.41568627 0.34509804]\n",
      "   ...\n",
      "   [0.27843137 0.38039216 0.32156863]\n",
      "   [0.3254902  0.42352941 0.36862745]\n",
      "   [0.33333333 0.42745098 0.37254902]]\n",
      "\n",
      "  [[0.1254902  0.2        0.12941176]\n",
      "   [0.21960784 0.29803922 0.22352941]\n",
      "   [0.34509804 0.42352941 0.34901961]\n",
      "   ...\n",
      "   [0.32941176 0.43137255 0.37254902]\n",
      "   [0.34509804 0.44313725 0.38431373]\n",
      "   [0.3254902  0.42352941 0.36470588]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06666667 0.12941176 0.07058824]\n",
      "   [0.0627451  0.12156863 0.0627451 ]\n",
      "   [0.01960784 0.08235294 0.01568627]\n",
      "   ...\n",
      "   [0.45490196 0.56470588 0.50196078]\n",
      "   [0.43137255 0.54509804 0.48235294]\n",
      "   [0.44313725 0.55686275 0.49803922]]\n",
      "\n",
      "  [[0.04705882 0.10588235 0.05098039]\n",
      "   [0.03137255 0.08627451 0.03529412]\n",
      "   [0.01176471 0.07058824 0.00784314]\n",
      "   ...\n",
      "   [0.47058824 0.58431373 0.52156863]\n",
      "   [0.4627451  0.57647059 0.51372549]\n",
      "   [0.48235294 0.59607843 0.5372549 ]]\n",
      "\n",
      "  [[0.02352941 0.07058824 0.02352941]\n",
      "   [0.         0.03921569 0.        ]\n",
      "   [0.         0.05490196 0.        ]\n",
      "   ...\n",
      "   [0.48235294 0.59607843 0.53333333]\n",
      "   [0.48235294 0.59607843 0.5372549 ]\n",
      "   [0.50980392 0.62745098 0.56470588]]]\n",
      "\n",
      "\n",
      " [[[0.33333333 0.43529412 0.36470588]\n",
      "   [0.36862745 0.47058824 0.39607843]\n",
      "   [0.35686275 0.45882353 0.38823529]\n",
      "   ...\n",
      "   [0.51372549 0.56078431 0.49803922]\n",
      "   [0.5372549  0.58823529 0.52156863]\n",
      "   [0.56470588 0.61568627 0.54509804]]\n",
      "\n",
      "  [[0.37647059 0.47843137 0.40784314]\n",
      "   [0.38431373 0.48627451 0.41568627]\n",
      "   [0.37647059 0.4745098  0.40784314]\n",
      "   ...\n",
      "   [0.46666667 0.5254902  0.45882353]\n",
      "   [0.47843137 0.5372549  0.46666667]\n",
      "   [0.50588235 0.56470588 0.49019608]]\n",
      "\n",
      "  [[0.41568627 0.51764706 0.45490196]\n",
      "   [0.36078431 0.4627451  0.4       ]\n",
      "   [0.36862745 0.47058824 0.40784314]\n",
      "   ...\n",
      "   [0.45490196 0.51372549 0.44705882]\n",
      "   [0.43921569 0.50196078 0.43137255]\n",
      "   [0.45882353 0.52156863 0.45098039]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.17254902 0.25490196 0.16862745]\n",
      "   [0.21960784 0.30588235 0.21960784]\n",
      "   [0.23921569 0.33333333 0.25098039]\n",
      "   ...\n",
      "   [0.38431373 0.47058824 0.39607843]\n",
      "   [0.40392157 0.49019608 0.41568627]\n",
      "   [0.43137255 0.51764706 0.44313725]]\n",
      "\n",
      "  [[0.15294118 0.23529412 0.14901961]\n",
      "   [0.19215686 0.27843137 0.18823529]\n",
      "   [0.21568627 0.30588235 0.21960784]\n",
      "   ...\n",
      "   [0.45882353 0.54509804 0.47058824]\n",
      "   [0.43529412 0.52156863 0.44705882]\n",
      "   [0.44705882 0.53333333 0.45882353]]\n",
      "\n",
      "  [[0.14509804 0.22745098 0.14117647]\n",
      "   [0.18431373 0.26666667 0.18039216]\n",
      "   [0.21176471 0.29803922 0.21176471]\n",
      "   ...\n",
      "   [0.51372549 0.6        0.5254902 ]\n",
      "   [0.47058824 0.55686275 0.48235294]\n",
      "   [0.45882353 0.54509804 0.47058824]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Start Training...\n",
      "Epoch: [ 1], step: [10], time: [5.2914], loss: [0.26741955]\n",
      "Epoch: [ 1], step: [20], time: [9.8307], loss: [0.12420551]\n",
      "Epoch: [ 1], step: [30], time: [13.9746], loss: [0.19889694]\n",
      "Epoch: [ 1], step: [40], time: [18.4197], loss: [0.14837749]\n",
      "Epoch: [ 1], step: [50], time: [23.1074], loss: [0.13176635]\n",
      "Epoch: [ 1], step: [60], time: [26.9377], loss: [0.01586235]\n",
      "Epoch: [ 1], step: [70], time: [30.5182], loss: [0.02361333]\n",
      "Epoch: [ 1], step: [80], time: [35.6888], loss: [0.00288014]\n",
      "Epoch: [ 1], step: [90], time: [39.6543], loss: [0.00716053]\n",
      "Epoch: [ 1], step: [100], time: [43.5741], loss: [0.00931056]\n",
      "Epoch: [ 1], step: [110], time: [47.0611], loss: [0.00554266]\n",
      "Epoch: [ 1], step: [120], time: [51.2929], loss: [0.01047839]\n",
      "Epoch: [ 1], step: [130], time: [54.4445], loss: [0.00936430]\n",
      "Epoch: [ 1], step: [140], time: [57.6443], loss: [0.00664726]\n",
      "Epoch: [ 1], step: [150], time: [60.8237], loss: [0.01643269]\n",
      "Epoch: [ 1], step: [160], time: [64.2845], loss: [0.04117566]\n",
      "Epoch: [ 1], step: [170], time: [67.5819], loss: [0.00599440]\n",
      "Epoch: [ 1], step: [180], time: [70.7277], loss: [0.01291507]\n",
      "Epoch: [ 1], step: [190], time: [73.9889], loss: [0.00757441]\n",
      "Epoch: [ 1], step: [200], time: [78.3033], loss: [0.01212759]\n",
      "Epoch: [ 1], step: [210], time: [82.6905], loss: [0.00301599]\n",
      "Epoch: [ 1], step: [220], time: [86.1309], loss: [0.02122259]\n",
      "Epoch: [ 1], step: [230], time: [90.6271], loss: [0.00655262]\n",
      "Epoch: [ 1], step: [240], time: [94.5646], loss: [0.01636156]\n",
      "Epoch: [ 1], step: [250], time: [98.8770], loss: [0.00231475]\n",
      "Epoch: [ 1], step: [260], time: [102.4015], loss: [0.01181211]\n",
      "Epoch: [ 1], step: [270], time: [106.3997], loss: [0.02687622]\n",
      "Epoch: [ 1], step: [280], time: [109.8056], loss: [0.00103394]\n",
      "Epoch: [ 1], step: [290], time: [114.0714], loss: [0.00436771]\n",
      "Epoch: [ 1], step: [300], time: [119.1337], loss: [0.02610015]\n",
      "Epoch: [ 1], step: [310], time: [122.9989], loss: [0.00253968]\n",
      "Epoch: [ 1], step: [320], time: [126.6151], loss: [0.00653724]\n",
      "Epoch: [ 1], step: [330], time: [130.1124], loss: [0.01114277]\n",
      "Epoch: [ 1], step: [340], time: [133.6054], loss: [0.00083684]\n",
      "Epoch: [ 1], step: [350], time: [138.1555], loss: [0.00985929]\n",
      "Epoch: [ 1], step: [360], time: [141.9827], loss: [0.01093039]\n",
      "Epoch: [ 1], step: [370], time: [146.7172], loss: [0.00840548]\n"
     ]
    }
   ],
   "source": [
    "class this_config():\n",
    "    def __init__(self, is_train=True):\n",
    "        self.epoch = 1\n",
    "        self.image_size = 33\n",
    "        self.label_size = 21\n",
    "        self.c_dim = 3\n",
    "        self.is_train = is_train\n",
    "        self.scale = 3\n",
    "        self.stride = 21\n",
    "        self.checkpoint_dir = \"checkpoint\"\n",
    "        self.learning_rate = 1e-4\n",
    "        self.batch_size = 128\n",
    "        \n",
    "arg = this_config()\n",
    "print(\"Hello TA!  We are group 7. Thank you for your work for us. Hope you have a happy day!\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    FLAGS = arg\n",
    "    srcnn = SRCNN(sess,\n",
    "                  image_size = FLAGS.image_size,\n",
    "                  label_size = FLAGS.label_size,\n",
    "                  c_dim = FLAGS.c_dim)\n",
    "    srcnn.train(FLAGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
